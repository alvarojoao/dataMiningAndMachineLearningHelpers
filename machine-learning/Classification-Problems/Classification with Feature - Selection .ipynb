{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate the two training DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486048, 54)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1 = pd.read_csv('../hackerrank-predict-email-opens-dataset/training_dataset.csv/training_dataset.csv', header=0)  \n",
    "train_df2 = pd.read_csv('../hackerrank-predict-email-opens-dataset/training_dataset.csv/training_dataset_complement.csv', header=0)  \n",
    "train_df = pd.concat([train_df1,train_df2])\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping few columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_online</th>\n",
       "      <th>contest_login_count</th>\n",
       "      <th>contest_login_count_1_days</th>\n",
       "      <th>contest_login_count_30_days</th>\n",
       "      <th>contest_login_count_365_days</th>\n",
       "      <th>contest_login_count_7_days</th>\n",
       "      <th>contest_participation_count</th>\n",
       "      <th>contest_participation_count_1_days</th>\n",
       "      <th>contest_participation_count_30_days</th>\n",
       "      <th>contest_participation_count_365_days</th>\n",
       "      <th>...</th>\n",
       "      <th>submissions_count_contest</th>\n",
       "      <th>submissions_count_contest_1_days</th>\n",
       "      <th>submissions_count_contest_30_days</th>\n",
       "      <th>submissions_count_contest_365_days</th>\n",
       "      <th>submissions_count_contest_7_days</th>\n",
       "      <th>submissions_count_master</th>\n",
       "      <th>submissions_count_master_1_days</th>\n",
       "      <th>submissions_count_master_30_days</th>\n",
       "      <th>submissions_count_master_365_days</th>\n",
       "      <th>submissions_count_master_7_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.459520e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.461210e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.463411e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.462768e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461248e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    last_online  contest_login_count  contest_login_count_1_days  \\\n",
       "0  1.459520e+09                    1                           0   \n",
       "1  1.461210e+09                    3                           0   \n",
       "2  1.463411e+09                    3                           0   \n",
       "3  1.462768e+09                    3                           0   \n",
       "4  1.461248e+09                    5                           0   \n",
       "\n",
       "   contest_login_count_30_days  contest_login_count_365_days  \\\n",
       "0                            0                             1   \n",
       "1                            1                             3   \n",
       "2                            0                             3   \n",
       "3                            0                             3   \n",
       "4                            0                             5   \n",
       "\n",
       "   contest_login_count_7_days  contest_participation_count  \\\n",
       "0                           0                            1   \n",
       "1                           0                            3   \n",
       "2                           0                            3   \n",
       "3                           0                            3   \n",
       "4                           0                           13   \n",
       "\n",
       "   contest_participation_count_1_days  contest_participation_count_30_days  \\\n",
       "0                                   0                                    0   \n",
       "1                                   0                                    1   \n",
       "2                                   0                                    0   \n",
       "3                                   0                                    0   \n",
       "4                                   0                                    0   \n",
       "\n",
       "   contest_participation_count_365_days               ...                 \\\n",
       "0                                     1               ...                  \n",
       "1                                     3               ...                  \n",
       "2                                     3               ...                  \n",
       "3                                     3               ...                  \n",
       "4                                    13               ...                  \n",
       "\n",
       "   submissions_count_contest  submissions_count_contest_1_days  \\\n",
       "0                          0                                 0   \n",
       "1                         16                                 0   \n",
       "2                          0                                 0   \n",
       "3                         16                                 0   \n",
       "4                         17                                 0   \n",
       "\n",
       "   submissions_count_contest_30_days  submissions_count_contest_365_days  \\\n",
       "0                                  0                                   0   \n",
       "1                                  3                                  16   \n",
       "2                                  0                                   0   \n",
       "3                                  0                                  16   \n",
       "4                                  1                                  17   \n",
       "\n",
       "   submissions_count_contest_7_days submissions_count_master  \\\n",
       "0                                 0                       13   \n",
       "1                                 0                       83   \n",
       "2                                 0                       16   \n",
       "3                                 0                       85   \n",
       "4                                 0                       43   \n",
       "\n",
       "   submissions_count_master_1_days  submissions_count_master_30_days  \\\n",
       "0                                0                                 0   \n",
       "1                                0                                43   \n",
       "2                                0                                 3   \n",
       "3                                0                                 9   \n",
       "4                                0                                 0   \n",
       "\n",
       "   submissions_count_master_365_days  submissions_count_master_7_days  \n",
       "0                                 13                                0  \n",
       "1                                 83                                4  \n",
       "2                                 16                                0  \n",
       "3                                 85                                0  \n",
       "4                                 43                                0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(['user_id','mail_id','mail_type','clicked','hacker_timezone',\n",
    "                          'mail_category','sent_time','unsubscribed',\n",
    "                          'open_time','click_time','unsubscribe_time','hacker_created_at'], axis=1) \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Boolean to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486048, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['opened'] = train_df.opened.map({True:1,False:0}).astype(int)\n",
    "train_df['hacker_confirmation'] = train_df.hacker_confirmation.map({True:1,False:0}).astype(int)\n",
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows with NA or Null Values (last_online is the only attribute with NA or Null values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485471, 42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.dropna(subset=['last_online'],axis=0)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting Columns to data constancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485471, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.reindex_axis(sorted(train_df.columns), axis=1)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding opened attribute to the first column of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opened</th>\n",
       "      <th>contest_login_count</th>\n",
       "      <th>contest_login_count_1_days</th>\n",
       "      <th>contest_login_count_30_days</th>\n",
       "      <th>contest_login_count_365_days</th>\n",
       "      <th>contest_login_count_7_days</th>\n",
       "      <th>contest_participation_count</th>\n",
       "      <th>contest_participation_count_1_days</th>\n",
       "      <th>contest_participation_count_30_days</th>\n",
       "      <th>contest_participation_count_365_days</th>\n",
       "      <th>...</th>\n",
       "      <th>submissions_count_contest</th>\n",
       "      <th>submissions_count_contest_1_days</th>\n",
       "      <th>submissions_count_contest_30_days</th>\n",
       "      <th>submissions_count_contest_365_days</th>\n",
       "      <th>submissions_count_contest_7_days</th>\n",
       "      <th>submissions_count_master</th>\n",
       "      <th>submissions_count_master_1_days</th>\n",
       "      <th>submissions_count_master_30_days</th>\n",
       "      <th>submissions_count_master_365_days</th>\n",
       "      <th>submissions_count_master_7_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   opened  contest_login_count  contest_login_count_1_days  \\\n",
       "0       1                    1                           0   \n",
       "1       0                    3                           0   \n",
       "2       0                    3                           0   \n",
       "3       0                    3                           0   \n",
       "4       0                    5                           0   \n",
       "\n",
       "   contest_login_count_30_days  contest_login_count_365_days  \\\n",
       "0                            0                             1   \n",
       "1                            1                             3   \n",
       "2                            0                             3   \n",
       "3                            0                             3   \n",
       "4                            0                             5   \n",
       "\n",
       "   contest_login_count_7_days  contest_participation_count  \\\n",
       "0                           0                            1   \n",
       "1                           0                            3   \n",
       "2                           0                            3   \n",
       "3                           0                            3   \n",
       "4                           0                           13   \n",
       "\n",
       "   contest_participation_count_1_days  contest_participation_count_30_days  \\\n",
       "0                                   0                                    0   \n",
       "1                                   0                                    1   \n",
       "2                                   0                                    0   \n",
       "3                                   0                                    0   \n",
       "4                                   0                                    0   \n",
       "\n",
       "   contest_participation_count_365_days               ...                 \\\n",
       "0                                     1               ...                  \n",
       "1                                     3               ...                  \n",
       "2                                     3               ...                  \n",
       "3                                     3               ...                  \n",
       "4                                    13               ...                  \n",
       "\n",
       "   submissions_count_contest  submissions_count_contest_1_days  \\\n",
       "0                          0                                 0   \n",
       "1                         16                                 0   \n",
       "2                          0                                 0   \n",
       "3                         16                                 0   \n",
       "4                         17                                 0   \n",
       "\n",
       "   submissions_count_contest_30_days  submissions_count_contest_365_days  \\\n",
       "0                                  0                                   0   \n",
       "1                                  3                                  16   \n",
       "2                                  0                                   0   \n",
       "3                                  0                                  16   \n",
       "4                                  1                                  17   \n",
       "\n",
       "   submissions_count_contest_7_days  submissions_count_master  \\\n",
       "0                                 0                        13   \n",
       "1                                 0                        83   \n",
       "2                                 0                        16   \n",
       "3                                 0                        85   \n",
       "4                                 0                        43   \n",
       "\n",
       "   submissions_count_master_1_days  submissions_count_master_30_days  \\\n",
       "0                                0                                 0   \n",
       "1                                0                                43   \n",
       "2                                0                                 3   \n",
       "3                                0                                 9   \n",
       "4                                0                                 0   \n",
       "\n",
       "   submissions_count_master_365_days  submissions_count_master_7_days  \n",
       "0                                 13                                0  \n",
       "1                                 83                                4  \n",
       "2                                 16                                0  \n",
       "3                                 85                                0  \n",
       "4                                 43                                0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.reindex_axis(['opened'] + list([col for col in train_df.columns if col != 'opened']), axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NA found\n"
     ]
    }
   ],
   "source": [
    "hasany = False\n",
    "for cl in train_df.columns.values:\n",
    "    hasNa = train_df[cl].isnull().sum() > 0\n",
    "    if hasNa:\n",
    "        hasany = True\n",
    "        print cl,train_df[cl].isnull().sum()\n",
    "if not hasany:\n",
    "    print 'No NA found'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data types for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened int32\n",
      "contest_login_count int64\n",
      "contest_login_count_1_days int64\n",
      "contest_login_count_30_days int64\n",
      "contest_login_count_365_days int64\n",
      "contest_login_count_7_days int64\n",
      "contest_participation_count int64\n",
      "contest_participation_count_1_days int64\n",
      "contest_participation_count_30_days int64\n",
      "contest_participation_count_365_days int64\n",
      "contest_participation_count_7_days int64\n",
      "forum_comments_count int64\n",
      "forum_count int64\n",
      "forum_expert_count int64\n",
      "forum_questions_count int64\n",
      "hacker_confirmation int32\n",
      "ipn_count int64\n",
      "ipn_count_1_days int64\n",
      "ipn_count_30_days int64\n",
      "ipn_count_365_days int64\n",
      "ipn_count_7_days int64\n",
      "ipn_read int64\n",
      "ipn_read_1_days int64\n",
      "ipn_read_30_days int64\n",
      "ipn_read_365_days int64\n",
      "ipn_read_7_days int64\n",
      "last_online float64\n",
      "submissions_count int64\n",
      "submissions_count_1_days int64\n",
      "submissions_count_30_days int64\n",
      "submissions_count_365_days int64\n",
      "submissions_count_7_days int64\n",
      "submissions_count_contest int64\n",
      "submissions_count_contest_1_days int64\n",
      "submissions_count_contest_30_days int64\n",
      "submissions_count_contest_365_days int64\n",
      "submissions_count_contest_7_days int64\n",
      "submissions_count_master int64\n",
      "submissions_count_master_1_days int64\n",
      "submissions_count_master_30_days int64\n",
      "submissions_count_master_365_days int64\n",
      "submissions_count_master_7_days int64\n"
     ]
    }
   ],
   "source": [
    "for cl in train_df.columns.values:\n",
    "    print cl,train_df[cl].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "train_data = train_df.values\n",
    "x_train_all = train_data[0::,1::]\n",
    "y_train_all = train_data[0::,0]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[0::,1::], train_data[0::,0], \n",
    "                            test_size = 0.2, random_state = 123) # Split training/test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Variance with Threshold -> VarianceThreshold\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.92169497e+01   1.15235800e-02   8.17802660e-01   3.18695098e+01\n",
      "   1.96381864e-01   1.52219968e+02   2.69246393e-02   2.17488492e+00\n",
      "   8.65012424e+01   4.52408418e-01   8.25390492e+00   1.23537944e+01\n",
      "   6.35134354e-02   1.84476335e-01   7.62243473e-02   8.78124989e+02\n",
      "   4.11418971e-01   7.17472235e+01   8.28937683e+02   8.23140625e+00\n",
      "   5.02016422e+01   1.75134449e-02   3.03373213e+00   4.46147079e+01\n",
      "   3.95243702e-01   1.08753180e+13   1.47458630e+04   2.45907948e+00\n",
      "   5.44221499e+02   8.05620176e+03   7.78755482e+01   6.09337880e+03\n",
      "   4.87003753e-01   6.19974722e+01   2.37681954e+03   1.03736998e+01\n",
      "   4.60234296e+03   1.87207125e+00   4.18513016e+02   3.39549336e+03\n",
      "   6.19790667e+01]\n",
      "(388376L, 41L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.83      0.81     64915\n",
      "        1.0       0.62      0.55      0.58     32180\n",
      "\n",
      "avg / total       0.73      0.74      0.73     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selectionAttributes = VarianceThreshold()\n",
    "model = selectionAttributes.fit(x_train)\n",
    "\n",
    "print model.variances_ \n",
    "\n",
    "x_train_selected = model.transform(x_train)\n",
    "x_test_selected = model.transform(x_test)\n",
    "print x_train_selected.shape\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate feature selection\n",
    "----------\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. <br/> It can be seen as a preprocessing step to an estimator. \n",
    "http://stats.stackexchange.com/questions/80002/categorize-statistical-tests-into-univariate-and-multivariate-methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<div><ul class=\"simple\">\n",
    "<li>For regression: <a class=\"reference internal\" href=\"generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression\" title=\"sklearn.feature_selection.f_regression\"><code class=\"xref py py-func docutils literal\"><span class=\"pre\">f_regression</span></code></a></li>\n",
    "<li>For classification: <a class=\"reference internal\" href=\"generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2\" title=\"sklearn.feature_selection.chi2\"><code class=\"xref py py-func docutils literal\"><span class=\"pre\">chi2</span></code></a> or <a class=\"reference internal\" href=\"generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif\" title=\"sklearn.feature_selection.f_classif\"><code class=\"xref py py-func docutils literal\"><span class=\"pre\">f_classif</span></code></a></li>\n",
    "</ul>\n",
    "</div></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GenericUnivariateSelect\n",
    "----------\n",
    "\n",
    "#### Univariate feature selector with configurable strategy.\n",
    "\n",
    "#### GENERAL WAY TO WORK WITH FEATURE SELECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[  2.48813908e+02   7.87559378e+01   1.44857603e+03   7.04695292e+01\n",
      "   8.43626811e+02   9.46497187e+02   1.34077011e+02   1.05899770e+03\n",
      "   5.73707629e+02   7.96595558e+02   1.90112017e+02   4.07692114e+02\n",
      "   2.57257414e+01   8.79517977e+01   1.86700852e+02   3.51098457e+03\n",
      "   3.66416782e+02   6.54319661e+03   3.45027584e+03   2.59248873e+03\n",
      "   3.55310722e+03   3.54623288e+02   4.23154521e+03   3.74444521e+03\n",
      "   1.87956167e+03   5.65882615e+06   2.84894703e+03   5.24720421e+03\n",
      "   6.05739875e+04   2.95700180e+03   3.23039997e+04   1.63879825e+03\n",
      "   1.42097800e+03   8.98072725e+03   7.06184020e+02   3.46894686e+03\n",
      "   1.39594723e+03   3.83441289e+03   5.15939866e+04   2.25674138e+03\n",
      "   2.90630196e+04]\n",
      "Pvalues\n",
      "[  4.70999932e-056   7.02771840e-019   0.00000000e+000   4.67430860e-017\n",
      "   1.76651431e-185   7.65896532e-208   5.25568103e-031   2.69559007e-232\n",
      "   8.76621651e-127   2.96653921e-175   3.00524783e-043   1.16546016e-090\n",
      "   3.93542719e-007   6.70691312e-021   1.66915331e-042   0.00000000e+000\n",
      "   1.12818893e-081   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   4.17226342e-079   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   5.80616210e-311   0.00000000e+000   1.35193819e-155   0.00000000e+000\n",
      "   1.59626541e-305   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000]\n",
      "(388376L, 40L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.83      0.81     64915\n",
      "        1.0       0.62      0.55      0.58     32180\n",
      "\n",
      "avg / total       0.73      0.74      0.73     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "\n",
    "model = GenericUnivariateSelect(chi2, 'k_best',40).fit(x_train, y_train)\n",
    "\n",
    "print \"Scores\"\n",
    "print model.scores_ \n",
    "print \"Pvalues\"\n",
    "print model.pvalues_ \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE - Recursive feature elimination\n",
    "----\n",
    "Feature ranking with recursive feature elimination.<br/>\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. <br/>First, the estimator is trained on the initial set of features and weights are assigned to each one of them. Then, features whose absolute weights are the smallest are pruned from the current set features. <br/>That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support - Mask\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False]\n",
      "Ranking\n",
      "[17 41 27 20 33 16 36 21  8 25 31 26 38 37 30  7 24  5  3 11 12 39 23 18 32\n",
      "  1  6 28  9  2 14 13 40 29 19 35  4 34 15 10 22]\n",
      "(388376L, 1L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.87      0.80     64915\n",
      "        1.0       0.60      0.39      0.47     32180\n",
      "\n",
      "avg / total       0.70      0.71      0.69     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "\n",
    "rfe = RFE(estimator=hipotese, n_features_to_select=1, step=1)\n",
    "\n",
    "model = rfe.fit(x_train, y_train)\n",
    "\n",
    "print \"Support - Mask\"\n",
    "print model.support_  \n",
    "print \"Ranking\"\n",
    "print model.ranking_  \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "# hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    " \n",
    "hipotese = model.estimator_\n",
    "\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFECV - Recursive feature elimination with cross-validation\n",
    "------\n",
    "A recursive feature elimination example with automatic tuning of the number of features selected with cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEcCAYAAAAC+llsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyaIwCSGEULL/D4rwiNUjcBgOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12312cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "\n",
    "rfecv = RFECV(estimator=hipotese, step=1, cv=StratifiedKFold(y_train_all, 3),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(x_train_all, y_train_all)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection using SelectFromModel\n",
    "------\n",
    "\n",
    "`SelectFromModel` is a meta-transformer that can be used along with any estimator that has a `coef_` or `feature_importances_` attribute after fitting. <br/>\n",
    "The features are considered unimportant and removed, if the corresponding `coef_` or `feature_importances_` values are below the provided threshold parameter. Apart from specifying the threshold numerically, there are build-in heuristics for finding a threshold using a string argument.\n",
    "\n",
    "##### Available heuristics are “mean”, “median” and float multiples of these like “0.1*mean”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388376L, 39L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.99      0.80     64915\n",
      "        1.0       0.47      0.02      0.03     32180\n",
      "\n",
      "avg / total       0.60      0.67      0.55     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "\n",
    "model = SelectFromModel(lsvc, prefit=False)\n",
    "model = model.fit(x_train, y_train)\n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "# hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    " \n",
    "hipotese = model.estimator_\n",
    "\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection using SelectFromModel and LinearSVC \n",
    "## Changing threshold from SelectFromModel object\n",
    "#### ps: working to reduce dimensionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of features:\n",
      "23\n",
      "Training data shape:\n",
      "(388376L, 2L)\n",
      "Support Indexed = True from feature selection:\n",
      "[ 2 14]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      1.00      0.80     64915\n",
      "        1.0       0.14      0.00      0.00     32180\n",
      "\n",
      "avg / total       0.49      0.67      0.54     97095\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAEZCAYAAADfWo+LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVxRBzUoHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130eb048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "\n",
    "model = SelectFromModel(lsvc, prefit=False,threshold=0.0025)\n",
    "model = model.fit(x_train, y_train)\n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "n_features = x_train_selected.shape[1] \n",
    "print \"Initial number of features:\"\n",
    "print n_features\n",
    "\n",
    "while n_features > 2:\n",
    "    model.threshold += 0.0001\n",
    "    x_train_selected = model.transform(x_train)\n",
    "    n_features = x_train_selected.shape[1]\n",
    "\n",
    "print \"Training data shape:\"\n",
    "print x_train_selected.shape\n",
    "\n",
    "print \"Support Indexed = True from feature selection:\"\n",
    "print model.get_support(True)\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    " \n",
    "# hipotese = model.estimator_\n",
    "\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n",
    "\n",
    "\n",
    "# Plot the selected two features from X.\n",
    "plt.title(\n",
    "    \"Features selected from Boston using SelectFromModel with \"\n",
    "    \"threshold %0.3f.\" % model.threshold)\n",
    "feature1 = x_train_selected[:, 0]\n",
    "feature2 = x_train_selected[:, 1] \n",
    "plt.plot(feature1, feature2, 'r.')\n",
    "plt.xlabel(\"Feature number 1\")\n",
    "plt.ylabel(\"Feature number 2\")\n",
    "plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix - 1\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chi2\n",
    "------\n",
    "#### Compute chi-squared stats between each non-negative feature and class.\n",
    "#### This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.\n",
    "##### Recall that the chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[  2.48813908e+02   7.87559378e+01   1.44857603e+03   7.04695292e+01\n",
      "   8.43626811e+02   9.46497187e+02   1.34077011e+02   1.05899770e+03\n",
      "   5.73707629e+02   7.96595558e+02   1.90112017e+02   4.07692114e+02\n",
      "   2.57257414e+01   8.79517977e+01   1.86700852e+02   3.51098457e+03\n",
      "   3.66416782e+02   6.54319661e+03   3.45027584e+03   2.59248873e+03\n",
      "   3.55310722e+03   3.54623288e+02   4.23154521e+03   3.74444521e+03\n",
      "   1.87956167e+03   5.65882615e+06   2.84894703e+03   5.24720421e+03\n",
      "   6.05739875e+04   2.95700180e+03   3.23039997e+04   1.63879825e+03\n",
      "   1.42097800e+03   8.98072725e+03   7.06184020e+02   3.46894686e+03\n",
      "   1.39594723e+03   3.83441289e+03   5.15939866e+04   2.25674138e+03\n",
      "   2.90630196e+04]\n",
      "Pvalues\n",
      "[  4.70999932e-056   7.02771840e-019   0.00000000e+000   4.67430860e-017\n",
      "   1.76651431e-185   7.65896532e-208   5.25568103e-031   2.69559007e-232\n",
      "   8.76621651e-127   2.96653921e-175   3.00524783e-043   1.16546016e-090\n",
      "   3.93542719e-007   6.70691312e-021   1.66915331e-042   0.00000000e+000\n",
      "   1.12818893e-081   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   4.17226342e-079   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   5.80616210e-311   0.00000000e+000   1.35193819e-155   0.00000000e+000\n",
      "   1.59626541e-305   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000]\n",
      "(388376L, 2L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.86      0.82     64915\n",
      "        1.0       0.64      0.50      0.56     32180\n",
      "\n",
      "avg / total       0.73      0.74      0.73     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "\n",
    "model = SelectKBest(chi2, k=2).fit(x_train, y_train)\n",
    "\n",
    "print \"Scores\"\n",
    "print model.scores_ \n",
    "print \"Pvalues\"\n",
    "print model.pvalues_ \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_classif\n",
    "------\n",
    "#### Compute the ANOVA F-value for the provided sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[   15.56719078    66.28201378   933.98776104     6.39787658   699.13901104\n",
      "    36.33378924    86.86163536   436.64180941    31.11640653   487.73946853\n",
      "     8.72054615    17.72135466     9.28109587    31.98597646  2258.77950748\n",
      "    97.28037691   216.66952462   472.75284483    99.86430699   508.38300944\n",
      "   183.20088034   283.82929815   617.96746467   202.44402531   570.88755858\n",
      "   760.73900966    11.16031246   432.06786839  1188.1422688     17.84529666\n",
      "  1234.56494106     4.60066622   139.3669068    232.50012686     4.0076796\n",
      "   162.4083098     12.33216028   316.73754995  1117.41878851    23.34832107\n",
      "  1167.00793315]\n",
      "Pvalues\n",
      "[  7.96383282e-005   3.91948422e-016   7.03785512e-205   1.14260863e-002\n",
      "   6.30675395e-154   1.66405351e-009   1.16964844e-020   6.58912469e-097\n",
      "   2.43169834e-008   5.15704926e-108   3.14662606e-003   2.55796921e-005\n",
      "   2.31546397e-003   1.55398194e-008   0.00000000e+000   6.05488956e-023\n",
      "   4.96718066e-049   9.32023104e-105   1.64276063e-023   1.68461416e-112\n",
      "   9.90953822e-042   1.15828125e-063   2.64739303e-136   6.28163802e-046\n",
      "   4.44212262e-126   2.69387581e-167   8.35737174e-004   6.50444940e-096\n",
      "   5.71261000e-260   2.39665296e-005   5.00426227e-270   3.19601528e-002\n",
      "   3.70821602e-032   1.75936012e-052   4.52941402e-002   3.42726500e-037\n",
      "   4.45271356e-004   7.93875459e-071   1.20797433e-244   1.35212870e-006\n",
      "   2.16821987e-255]\n",
      "(388376L, 2L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      1.00      0.80     64915\n",
      "        1.0       0.49      0.00      0.00     32180\n",
      "\n",
      "avg / total       0.61      0.67      0.54     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "\n",
    "model = SelectKBest(f_classif, k=2).fit(x_train, y_train)\n",
    "\n",
    "print \"Scores\"\n",
    "print model.scores_ \n",
    "print \"Pvalues\"\n",
    "print model.pvalues_ \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectPercentile\n",
    "-----\n",
    "##### Select features according to a percentile of the highest scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[   15.56719078    66.28201378   933.98776104     6.39787658   699.13901104\n",
      "    36.33378924    86.86163536   436.64180941    31.11640653   487.73946853\n",
      "     8.72054615    17.72135466     9.28109587    31.98597646  2258.77950748\n",
      "    97.28037691   216.66952462   472.75284483    99.86430699   508.38300944\n",
      "   183.20088034   283.82929815   617.96746467   202.44402531   570.88755858\n",
      "   760.73900966    11.16031246   432.06786839  1188.1422688     17.84529666\n",
      "  1234.56494106     4.60066622   139.3669068    232.50012686     4.0076796\n",
      "   162.4083098     12.33216028   316.73754995  1117.41878851    23.34832107\n",
      "  1167.00793315]\n",
      "Pvalues\n",
      "[  7.96383282e-005   3.91948422e-016   7.03785512e-205   1.14260863e-002\n",
      "   6.30675395e-154   1.66405351e-009   1.16964844e-020   6.58912469e-097\n",
      "   2.43169834e-008   5.15704926e-108   3.14662606e-003   2.55796921e-005\n",
      "   2.31546397e-003   1.55398194e-008   0.00000000e+000   6.05488956e-023\n",
      "   4.96718066e-049   9.32023104e-105   1.64276063e-023   1.68461416e-112\n",
      "   9.90953822e-042   1.15828125e-063   2.64739303e-136   6.28163802e-046\n",
      "   4.44212262e-126   2.69387581e-167   8.35737174e-004   6.50444940e-096\n",
      "   5.71261000e-260   2.39665296e-005   5.00426227e-270   3.19601528e-002\n",
      "   3.70821602e-032   1.75936012e-052   4.52941402e-002   3.42726500e-037\n",
      "   4.45271356e-004   7.93875459e-071   1.20797433e-244   1.35212870e-006\n",
      "   2.16821987e-255]\n",
      "(388376L, 36L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.83      0.81     64915\n",
      "        1.0       0.61      0.55      0.58     32180\n",
      "\n",
      "avg / total       0.73      0.74      0.73     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "\n",
    "model = SelectPercentile(f_classif, percentile=90).fit(x_train, y_train)\n",
    "\n",
    "print \"Scores\"\n",
    "print model.scores_ \n",
    "print \"Pvalues\"\n",
    "print model.pvalues_ \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFpr\n",
    "-----\n",
    "\n",
    "#### Filter: Select the pvalues below alpha based on a FPR test. <br/>\n",
    "#### FPR test stands for False Positive Rate test. It controls the total amount of false detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[  2.48813908e+02   7.87559378e+01   1.44857603e+03   7.04695292e+01\n",
      "   8.43626811e+02   9.46497187e+02   1.34077011e+02   1.05899770e+03\n",
      "   5.73707629e+02   7.96595558e+02   1.90112017e+02   4.07692114e+02\n",
      "   2.57257414e+01   8.79517977e+01   1.86700852e+02   3.51098457e+03\n",
      "   3.66416782e+02   6.54319661e+03   3.45027584e+03   2.59248873e+03\n",
      "   3.55310722e+03   3.54623288e+02   4.23154521e+03   3.74444521e+03\n",
      "   1.87956167e+03   5.65882615e+06   2.84894703e+03   5.24720421e+03\n",
      "   6.05739875e+04   2.95700180e+03   3.23039997e+04   1.63879825e+03\n",
      "   1.42097800e+03   8.98072725e+03   7.06184020e+02   3.46894686e+03\n",
      "   1.39594723e+03   3.83441289e+03   5.15939866e+04   2.25674138e+03\n",
      "   2.90630196e+04]\n",
      "Pvalues\n",
      "[  4.70999932e-056   7.02771840e-019   0.00000000e+000   4.67430860e-017\n",
      "   1.76651431e-185   7.65896532e-208   5.25568103e-031   2.69559007e-232\n",
      "   8.76621651e-127   2.96653921e-175   3.00524783e-043   1.16546016e-090\n",
      "   3.93542719e-007   6.70691312e-021   1.66915331e-042   0.00000000e+000\n",
      "   1.12818893e-081   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   4.17226342e-079   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   5.80616210e-311   0.00000000e+000   1.35193819e-155   0.00000000e+000\n",
      "   1.59626541e-305   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000]\n",
      "(388376L, 41L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.83      0.81     64915\n",
      "        1.0       0.62      0.55      0.58     32180\n",
      "\n",
      "avg / total       0.73      0.74      0.73     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFpr\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "\n",
    "model = SelectFpr(chi2, alpha=0.001).fit(x_train, y_train)\n",
    "\n",
    "print \"Scores\"\n",
    "print model.scores_ \n",
    "print \"Pvalues\"\n",
    "print model.pvalues_ \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFwe\n",
    "-------\n",
    "\n",
    "#### Filter: Select the p-values corresponding to Family-wise error rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[  2.48813908e+02   7.87559378e+01   1.44857603e+03   7.04695292e+01\n",
      "   8.43626811e+02   9.46497187e+02   1.34077011e+02   1.05899770e+03\n",
      "   5.73707629e+02   7.96595558e+02   1.90112017e+02   4.07692114e+02\n",
      "   2.57257414e+01   8.79517977e+01   1.86700852e+02   3.51098457e+03\n",
      "   3.66416782e+02   6.54319661e+03   3.45027584e+03   2.59248873e+03\n",
      "   3.55310722e+03   3.54623288e+02   4.23154521e+03   3.74444521e+03\n",
      "   1.87956167e+03   5.65882615e+06   2.84894703e+03   5.24720421e+03\n",
      "   6.05739875e+04   2.95700180e+03   3.23039997e+04   1.63879825e+03\n",
      "   1.42097800e+03   8.98072725e+03   7.06184020e+02   3.46894686e+03\n",
      "   1.39594723e+03   3.83441289e+03   5.15939866e+04   2.25674138e+03\n",
      "   2.90630196e+04]\n",
      "Pvalues\n",
      "[  4.70999932e-056   7.02771840e-019   0.00000000e+000   4.67430860e-017\n",
      "   1.76651431e-185   7.65896532e-208   5.25568103e-031   2.69559007e-232\n",
      "   8.76621651e-127   2.96653921e-175   3.00524783e-043   1.16546016e-090\n",
      "   3.93542719e-007   6.70691312e-021   1.66915331e-042   0.00000000e+000\n",
      "   1.12818893e-081   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   4.17226342e-079   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   5.80616210e-311   0.00000000e+000   1.35193819e-155   0.00000000e+000\n",
      "   1.59626541e-305   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000]\n",
      "(388376L, 41L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.83      0.81     64915\n",
      "        1.0       0.62      0.55      0.58     32180\n",
      "\n",
      "avg / total       0.73      0.74      0.73     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFwe\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "\n",
    "model = SelectFwe(chi2, alpha=0.001).fit(x_train, y_train)\n",
    "\n",
    "print \"Scores\"\n",
    "print model.scores_ \n",
    "print \"Pvalues\"\n",
    "print model.pvalues_ \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFdr\n",
    "-------\n",
    "### Filter: Select the p-values for an estimated false discovery rate <br/>\n",
    "### This uses the Benjamini-Hochberg procedure. `alpha` is an upper bound on the expected false discovery rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[  2.48813908e+02   7.87559378e+01   1.44857603e+03   7.04695292e+01\n",
      "   8.43626811e+02   9.46497187e+02   1.34077011e+02   1.05899770e+03\n",
      "   5.73707629e+02   7.96595558e+02   1.90112017e+02   4.07692114e+02\n",
      "   2.57257414e+01   8.79517977e+01   1.86700852e+02   3.51098457e+03\n",
      "   3.66416782e+02   6.54319661e+03   3.45027584e+03   2.59248873e+03\n",
      "   3.55310722e+03   3.54623288e+02   4.23154521e+03   3.74444521e+03\n",
      "   1.87956167e+03   5.65882615e+06   2.84894703e+03   5.24720421e+03\n",
      "   6.05739875e+04   2.95700180e+03   3.23039997e+04   1.63879825e+03\n",
      "   1.42097800e+03   8.98072725e+03   7.06184020e+02   3.46894686e+03\n",
      "   1.39594723e+03   3.83441289e+03   5.15939866e+04   2.25674138e+03\n",
      "   2.90630196e+04]\n",
      "Pvalues\n",
      "[  4.70999932e-056   7.02771840e-019   0.00000000e+000   4.67430860e-017\n",
      "   1.76651431e-185   7.65896532e-208   5.25568103e-031   2.69559007e-232\n",
      "   8.76621651e-127   2.96653921e-175   3.00524783e-043   1.16546016e-090\n",
      "   3.93542719e-007   6.70691312e-021   1.66915331e-042   0.00000000e+000\n",
      "   1.12818893e-081   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   4.17226342e-079   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   5.80616210e-311   0.00000000e+000   1.35193819e-155   0.00000000e+000\n",
      "   1.59626541e-305   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   0.00000000e+000]\n",
      "(388376L, 41L)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.83      0.81     64915\n",
      "        1.0       0.62      0.55      0.58     32180\n",
      "\n",
      "avg / total       0.73      0.74      0.73     97095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFdr\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "\n",
    "model = SelectFdr(chi2, alpha=0.001).fit(x_train, y_train)\n",
    "\n",
    "print \"Scores\"\n",
    "print model.scores_ \n",
    "print \"Pvalues\"\n",
    "print model.pvalues_ \n",
    "\n",
    "x_train_selected =  model.transform(x_train)\n",
    "\n",
    "print x_train_selected.shape\n",
    "\n",
    "x_test_selected =  model.transform(x_test)\n",
    "\n",
    "# hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "# hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "# hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train_selected, y_train)\n",
    "y_true, y_pred = y_test, hipotese.predict(x_test_selected) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
